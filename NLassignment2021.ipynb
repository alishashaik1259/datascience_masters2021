{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2S8I2ny-ovS"
   },
   "source": [
    "# NLE Assignment: Sentiment Classification\n",
    "\n",
    "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
    "\n",
    "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
    "\n",
    "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n",
    "\n",
    "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1gXQAZas-l9c"
   },
   "outputs": [],
   "source": [
    "candidateno=244859 #this MUST be updated to your candidate number so that you get a unique data sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nk8JTP88A8vs",
    "outputId": "949caba1-dcc7-483d-8271-3a466f728640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "#preliminary imports\n",
    "\n",
    "#set up nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "#for setting up training and testing data\n",
    "import random\n",
    "\n",
    "#useful other tools\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify.api import ClassifierI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BHBkzAccCVaZ"
   },
   "outputs": [],
   "source": [
    "#do not change the code in this cell\n",
    "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
    "    \"\"\"\n",
    "    Given corpus generator and ratio:\n",
    "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
    "\n",
    "    :param data: A corpus generator.\n",
    "    :param ratio: The proportion of training documents (default 0.7)\n",
    "    :return: a pair (tuple) of lists where the first element of the \n",
    "            pair is a list of the training data and the second is a list of the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = list(data)  \n",
    "    n = len(data)  \n",
    "    train_indices = random.sample(range(n), int(n * ratio))          \n",
    "    test_indices = list(set(range(n)) - set(train_indices))    \n",
    "    train = [data[i] for i in train_indices]           \n",
    "    test = [data[i] for i in test_indices]             \n",
    "    return (train, test)                       \n",
    " \n",
    "\n",
    "def get_train_test_data():\n",
    "    \n",
    "    #get ids of positive and negative movie reviews\n",
    "    pos_review_ids=movie_reviews.fileids('pos')\n",
    "    neg_review_ids=movie_reviews.fileids('neg')\n",
    "   \n",
    "    #split positive and negative data into training and testing sets\n",
    "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
    "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
    "    #add labels to the data and concatenate\n",
    "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
    "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
    "   \n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1N3LWwBYICPP"
   },
   "source": [
    "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJLegkdPFUJA",
    "outputId": "5c705723-2729-4984-fc51-941205afe583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of training data is 1400\n",
      "The amount of testing data is 600\n",
      "The representation of a single data item is below\n",
      "(['\"', 'the', 'fighting', 'sullivans', '\"', 'contains', ...], 'pos')\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "random.seed(candidateno)\n",
    "training_data,testing_data=get_train_test_data()\n",
    "print(\"The amount of training data is {}\".format(len(training_data)))\n",
    "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
    "print(\"The representation of a single data item is below\")\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_492e4egiwFi",
    "outputId": "2759b287-b10e-4bdb-bc2d-f4f5a31d0817"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['even', 'if', 'i', 'did', 'not', 'know', 'that', ...], 'pos')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hguoeaSbeOXi"
   },
   "source": [
    "1)  \n",
    "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
    "\n",
    "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
    "\n",
    "c) **Explain** what you have done and why\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1DhriMtsPiB"
   },
   "source": [
    "## **1.c.  Explanation on generation of list of 10 content words each from positive and negative reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSnOp26EaO0p"
   },
   "source": [
    "Here the data is taken from nltk movie_reviews corpus and it has been split into `pos_review_ids` and `neg_review_ids`, this was done by identifying the reviews with 'pos' fileid as `pos_review_ids` and with 'neg' as `neg_review_ids` using `get_train_test_data` function and this data is further divided into `pos_train_ids`, `pos_test_ids` and `neg_train_ids`, `neg_test_ids` datasets using and `split_data` function in the ratio of 70:30. And then the data was labelled as 'pos' and 'neg' and concatenated `pos_train_ids` , `neg_train_ids` as 'training' and `pos_test_ids` and `neg_test_ids` as 'testing'. After these steps, the amount of training data is 1400 data and testing data is 600. Here the random seed is constant(which is given as my candidate number). So that each and every time I run this I will get only the same data instead of random ones.\n",
    "\n",
    "After this, `training_word_frequency` and `testing_word_frequency` lists were generated by importing FreqDist fromnltk.probability library. This data was analysed and there are a large number of stop words in the data. Stopwords are non-content bearing high frequency words, which hold no information of the text sentiment. Some of the examples of stopwords in English are ‘The’, 'of', 'and', 'on', 'in' etc. So,these stopwords should be removed before training the model. And after that lemmatization is done on the data in order to bring together all the inflected forms of a word so they can be considered and analysed as a single item. For Example in English the verb 'go' may appear as 'goes', 'went', 'gone', 'going' , for all these forms the base form 'go' is the lemma for the word. These newly filtered pre-processed datasets were called `training_prepros` and `testing_prepros`. They have less vocabulary size when compared to earlier datasets. This vocabulary size reduction really helps in building an effective model. This pre-processed training and testing dataset is a list of tuples of freq_dist of doc(word and its frequency) and label.\n",
    "\n",
    "Now, the positive and negative freq_dist vocabulary is built from the pre-processed training data, which has 'pos' and 'neg' labels, and they are named as `pos_word_freq` and `neg_word_freq`. Then, the top 10 most frequent positive and negative words are filtered out by using `most_frequent_words` function which filtered the top 10 words in each category by sorting the difference from each category with another. These top 10 most common words in each category are turned into a list and named as `my_positive_word_list` and `my_negative_word_list`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qeaj1P4tqc4r"
   },
   "source": [
    "## **1.a and 1.b.  Generation of list of 10 content words each from *Positive* and *Negative* reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iuA2ZZXuQt6",
    "outputId": "b00de8fb-1c37-43cf-eb00-4a03994e4a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive reviews is 1000\n",
      "The number of negative reviews is 1000\n"
     ]
    }
   ],
   "source": [
    "pos_review_ids=movie_reviews.fileids('pos')\n",
    "neg_review_ids=movie_reviews.fileids('neg')\n",
    "\n",
    "print(\"The number of positive reviews is {}\".format(len(pos_review_ids)))\n",
    "print(\"The number of negative reviews is {}\".format(len(neg_review_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "28ZzBnZL1MrN"
   },
   "outputs": [],
   "source": [
    "training_word_frequency =[(FreqDist(doc), label ) for (doc,label) in training_data] #Generating each word and its frequency\n",
    "testing_word_frequency=[(FreqDist(doc), label ) for (doc,label) in testing_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Oj3ZKxMS1u8V"
   },
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "S4I8Ej3n0oCI"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "Wl = WordNetLemmatizer()\n",
    "def normalise(wordlist):\n",
    "    #lowered=[word.lower() for word in wordlist] \n",
    "    filtered=[word for word in wordlist if word.isalpha() and word not in stop]\n",
    "    lemmatizer_sentence=[Wl.lemmatize(word) for word in filtered]\n",
    "    return lemmatizer_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6KxTyE36ufl",
    "outputId": "3591fbe3-9812-44a7-c2c7-1df9bfc9af39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "msWNe3ZO04h2"
   },
   "outputs": [],
   "source": [
    "training_prepros=[(FreqDist(normalise(wordlist)), pos) for (wordlist,pos) in training_word_frequency]\n",
    "testing_prepros=[(FreqDist(normalise(wordlist)), pos) for (wordlist,pos) in testing_word_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gWAKuLINC8n",
    "outputId": "e6bea8b4-0334-4593-a509-34573958e1b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_prepros[0]) #training_prepros is a list of tuples of freq_dist of doc(word and its frequency) and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUB-4Vw6eOXj",
    "outputId": "e9a87637-8d25-4d71-ae8f-5049def52119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'fighting': 33,\n",
       "          'sullivan': 6,\n",
       "          'contains': 38,\n",
       "          'major': 92,\n",
       "          'plot': 280,\n",
       "          'development': 36,\n",
       "          'last': 218,\n",
       "          'ten': 37,\n",
       "          'minute': 170,\n",
       "          'every': 233,\n",
       "          'movie': 780,\n",
       "          'guide': 10,\n",
       "          'seen': 256,\n",
       "          'fit': 49,\n",
       "          'give': 284,\n",
       "          'away': 181,\n",
       "          'dramatic': 69,\n",
       "          'tension': 51,\n",
       "          'watching': 125,\n",
       "          'film': 934,\n",
       "          'knew': 32,\n",
       "          'exactly': 102,\n",
       "          'going': 207,\n",
       "          'happen': 61,\n",
       "          'worst': 35,\n",
       "          'thing': 408,\n",
       "          'viewing': 49,\n",
       "          'tread': 6,\n",
       "          'lightly': 7,\n",
       "          'ruin': 17,\n",
       "          'anyone': 108,\n",
       "          'reading': 33,\n",
       "          'review': 110,\n",
       "          'would': 383,\n",
       "          'advisable': 1,\n",
       "          'avoid': 28,\n",
       "          'material': 60,\n",
       "          'regarding': 12,\n",
       "          'revolves': 19,\n",
       "          'around': 228,\n",
       "          'family': 168,\n",
       "          'consists': 19,\n",
       "          'mother': 112,\n",
       "          'father': 142,\n",
       "          'sister': 57,\n",
       "          'five': 72,\n",
       "          'brother': 112,\n",
       "          'close': 91,\n",
       "          'despite': 112,\n",
       "          'occasional': 20,\n",
       "          'disagreement': 1,\n",
       "          'inseperable': 1,\n",
       "          'never': 307,\n",
       "          'stray': 6,\n",
       "          'one': 685,\n",
       "          'another': 276,\n",
       "          'friendship': 31,\n",
       "          'loyalty': 13,\n",
       "          'foundation': 9,\n",
       "          'picture': 200,\n",
       "          'first': 387,\n",
       "          'half': 127,\n",
       "          'follows': 59,\n",
       "          'young': 211,\n",
       "          'child': 168,\n",
       "          'various': 41,\n",
       "          'adventure': 52,\n",
       "          'four': 88,\n",
       "          'get': 592,\n",
       "          'fight': 110,\n",
       "          'local': 75,\n",
       "          'boy': 115,\n",
       "          'youngest': 3,\n",
       "          'inside': 60,\n",
       "          'church': 23,\n",
       "          'time': 624,\n",
       "          'come': 407,\n",
       "          'running': 88,\n",
       "          'assist': 7,\n",
       "          'properly': 11,\n",
       "          'exiting': 4,\n",
       "          'chapel': 2,\n",
       "          'awfully': 7,\n",
       "          'vague': 11,\n",
       "          'detail': 94,\n",
       "          'told': 76,\n",
       "          'essentially': 22,\n",
       "          'hour': 155,\n",
       "          'say': 277,\n",
       "          'go': 433,\n",
       "          'watch': 177,\n",
       "          'fine': 103,\n",
       "          'portrait': 20,\n",
       "          'stick': 33,\n",
       "          'together': 174,\n",
       "          'good': 429,\n",
       "          'bad': 184,\n",
       "          'see': 430,\n",
       "          'understand': 57,\n",
       "          'written': 128,\n",
       "          'way': 419,\n",
       "          'sometimes': 84,\n",
       "          'tip': 11,\n",
       "          'hat': 13,\n",
       "          'jump': 36,\n",
       "          'bandwagon': 1,\n",
       "          'enjoy': 84,\n",
       "          'ride': 62,\n",
       "          'saw': 73,\n",
       "          'truman': 17,\n",
       "          'show': 301,\n",
       "          'audience': 298,\n",
       "          'full': 108,\n",
       "          'teenager': 30,\n",
       "          'doubt': 61,\n",
       "          'drawn': 36,\n",
       "          'ace': 5,\n",
       "          'ventura': 3,\n",
       "          'hoping': 21,\n",
       "          'latest': 61,\n",
       "          'take': 464,\n",
       "          'fart': 2,\n",
       "          'joke': 77,\n",
       "          'surprised': 43,\n",
       "          'may': 216,\n",
       "          'realized': 35,\n",
       "          'actually': 191,\n",
       "          'something': 255,\n",
       "          'attentiveness': 1,\n",
       "          'crowd': 31,\n",
       "          'tell': 189,\n",
       "          'yet': 193,\n",
       "          'really': 298,\n",
       "          'seems': 224,\n",
       "          'comparison': 29,\n",
       "          'awful': 14,\n",
       "          'mountain': 24,\n",
       "          'crap': 18,\n",
       "          'spewed': 2,\n",
       "          'forth': 16,\n",
       "          'bowl': 7,\n",
       "          'hollywood': 143,\n",
       "          'far': 175,\n",
       "          'year': 472,\n",
       "          'alone': 60,\n",
       "          'make': 626,\n",
       "          'call': 99,\n",
       "          'end': 334,\n",
       "          'burbank': 8,\n",
       "          'side': 137,\n",
       "          'concerned': 29,\n",
       "          'well': 411,\n",
       "          'wanted': 48,\n",
       "          'win': 62,\n",
       "          'felt': 64,\n",
       "          'tribute': 15,\n",
       "          'jim': 43,\n",
       "          'carrey': 16,\n",
       "          'achieved': 11,\n",
       "          'legitimacy': 1,\n",
       "          'best': 334,\n",
       "          'viewed': 22,\n",
       "          'cold': 52,\n",
       "          'little': 319,\n",
       "          'foreknowledge': 1,\n",
       "          'possible': 75,\n",
       "          'unless': 18,\n",
       "          'medium': 41,\n",
       "          'blackout': 1,\n",
       "          'however': 236,\n",
       "          'probably': 143,\n",
       "          'know': 349,\n",
       "          'basic': 36,\n",
       "          'star': 294,\n",
       "          'capra': 6,\n",
       "          'esque': 18,\n",
       "          'everyman': 5,\n",
       "          'insurance': 9,\n",
       "          'agent': 51,\n",
       "          'living': 76,\n",
       "          'beautiful': 102,\n",
       "          'wife': 155,\n",
       "          'meryl': 7,\n",
       "          'laura': 18,\n",
       "          'linney': 7,\n",
       "          'south': 29,\n",
       "          'florida': 11,\n",
       "          'island': 24,\n",
       "          'town': 105,\n",
       "          'seahaven': 5,\n",
       "          'look': 300,\n",
       "          'like': 541,\n",
       "          'michael': 91,\n",
       "          'eisner': 3,\n",
       "          'idea': 131,\n",
       "          'perfect': 117,\n",
       "          'american': 174,\n",
       "          'small': 154,\n",
       "          'seem': 158,\n",
       "          'live': 101,\n",
       "          'middle': 57,\n",
       "          'class': 78,\n",
       "          'lifestyle': 11,\n",
       "          'complete': 61,\n",
       "          'working': 80,\n",
       "          'bud': 12,\n",
       "          'friendly': 23,\n",
       "          'neighbor': 22,\n",
       "          'interesting': 158,\n",
       "          'co': 79,\n",
       "          'worker': 43,\n",
       "          'tragedy': 35,\n",
       "          'past': 106,\n",
       "          'drowned': 3,\n",
       "          'horrible': 21,\n",
       "          'boating': 1,\n",
       "          'accident': 35,\n",
       "          'leaving': 64,\n",
       "          'dreadful': 4,\n",
       "          'fear': 67,\n",
       "          'water': 62,\n",
       "          'travel': 35,\n",
       "          'general': 64,\n",
       "          'overall': 78,\n",
       "          'life': 449,\n",
       "          'day': 266,\n",
       "          'leaf': 63,\n",
       "          'house': 88,\n",
       "          'work': 393,\n",
       "          'klieg': 1,\n",
       "          'light': 101,\n",
       "          'fall': 155,\n",
       "          'magically': 3,\n",
       "          'sky': 28,\n",
       "          'curious': 12,\n",
       "          'event': 99,\n",
       "          'lead': 160,\n",
       "          'discover': 38,\n",
       "          'rest': 113,\n",
       "          'world': 269,\n",
       "          'already': 84,\n",
       "          'prisoner': 29,\n",
       "          'biggest': 50,\n",
       "          'soundstage': 1,\n",
       "          'friend': 232,\n",
       "          'relative': 13,\n",
       "          'actor': 330,\n",
       "          'paid': 10,\n",
       "          'interact': 10,\n",
       "          'broadcast': 18,\n",
       "          'popular': 66,\n",
       "          'television': 59,\n",
       "          'program': 22,\n",
       "          'enjoyable': 58,\n",
       "          'magical': 20,\n",
       "          'verisimilitude': 2,\n",
       "          'painstakingly': 3,\n",
       "          'constructed': 13,\n",
       "          'niccol': 7,\n",
       "          'weir': 11,\n",
       "          'second': 122,\n",
       "          'man': 302,\n",
       "          'made': 256,\n",
       "          'structure': 26,\n",
       "          'visible': 6,\n",
       "          'space': 65,\n",
       "          'movement': 33,\n",
       "          'tracked': 4,\n",
       "          'ceaselessly': 1,\n",
       "          'camera': 102,\n",
       "          'scattered': 4,\n",
       "          'throughout': 112,\n",
       "          'button': 6,\n",
       "          'cam': 3,\n",
       "          'dashboard': 1,\n",
       "          'mirror': 16,\n",
       "          'big': 218,\n",
       "          'cut': 76,\n",
       "          'quite': 202,\n",
       "          'sure': 150,\n",
       "          'director': 344,\n",
       "          'omnipotent': 2,\n",
       "          'creator': 15,\n",
       "          'christof': 7,\n",
       "          'ed': 33,\n",
       "          'harris': 26,\n",
       "          'oversees': 1,\n",
       "          'control': 42,\n",
       "          'room': 82,\n",
       "          'built': 29,\n",
       "          'moon': 11,\n",
       "          'act': 95,\n",
       "          'offer': 86,\n",
       "          'plethora': 2,\n",
       "          'clue': 23,\n",
       "          'truth': 59,\n",
       "          'existence': 30,\n",
       "          'marlon': 6,\n",
       "          'noah': 7,\n",
       "          'emmerich': 8,\n",
       "          'always': 179,\n",
       "          'six': 50,\n",
       "          'pack': 18,\n",
       "          'beer': 10,\n",
       "          'exist': 23,\n",
       "          'eternal': 5,\n",
       "          'commercial': 25,\n",
       "          'endorsing': 1,\n",
       "          'hot': 41,\n",
       "          'household': 12,\n",
       "          'product': 29,\n",
       "          'people': 330,\n",
       "          'walking': 27,\n",
       "          'set': 280,\n",
       "          'pattern': 18,\n",
       "          'wonder': 98,\n",
       "          'pick': 39,\n",
       "          'earlier': 55,\n",
       "          'answer': 51,\n",
       "          'tend': 19,\n",
       "          'accept': 27,\n",
       "          'reality': 65,\n",
       "          'presented': 38,\n",
       "          'nevertheless': 30,\n",
       "          'begin': 194,\n",
       "          'grow': 23,\n",
       "          'restless': 9,\n",
       "          'dream': 91,\n",
       "          'escape': 68,\n",
       "          'fiji': 2,\n",
       "          'old': 227,\n",
       "          'college': 31,\n",
       "          'sweetheart': 5,\n",
       "          'natasha': 8,\n",
       "          'mcelhone': 5,\n",
       "          'supposedly': 18,\n",
       "          'convincing': 55,\n",
       "          'progenitor': 1,\n",
       "          'provocative': 2,\n",
       "          'concept': 51,\n",
       "          'stay': 79,\n",
       "          'underplaying': 1,\n",
       "          'allows': 53,\n",
       "          'subtle': 61,\n",
       "          'manipulation': 14,\n",
       "          'particularly': 95,\n",
       "          'poignant': 14,\n",
       "          'scene': 547,\n",
       "          'confides': 2,\n",
       "          'sincerity': 8,\n",
       "          'gladly': 3,\n",
       "          'step': 52,\n",
       "          'front': 45,\n",
       "          'bus': 15,\n",
       "          'line': 203,\n",
       "          'fed': 16,\n",
       "          'earpiece': 1,\n",
       "          'abject': 1,\n",
       "          'cruelty': 11,\n",
       "          'subjected': 8,\n",
       "          'hit': 108,\n",
       "          'home': 154,\n",
       "          'moment': 204,\n",
       "          'derives': 4,\n",
       "          'much': 394,\n",
       "          'success': 86,\n",
       "          'playing': 114,\n",
       "          'secret': 62,\n",
       "          'paranoid': 14,\n",
       "          'fantasy': 46,\n",
       "          'least': 152,\n",
       "          'doubted': 6,\n",
       "          'place': 220,\n",
       "          'closest': 10,\n",
       "          'u': 265,\n",
       "          'ultimately': 52,\n",
       "          'rise': 41,\n",
       "          'artifice': 3,\n",
       "          'raise': 30,\n",
       "          'real': 235,\n",
       "          'question': 128,\n",
       "          'relationship': 130,\n",
       "          'humankind': 5,\n",
       "          'god': 68,\n",
       "          'think': 232,\n",
       "          'resent': 4,\n",
       "          'abandonment': 2,\n",
       "          'paradise': 13,\n",
       "          'credit': 100,\n",
       "          'allowing': 18,\n",
       "          'magic': 35,\n",
       "          'screenplay': 79,\n",
       "          'kind': 163,\n",
       "          'role': 302,\n",
       "          'jimmy': 19,\n",
       "          'stewart': 11,\n",
       "          'born': 36,\n",
       "          'play': 315,\n",
       "          'try': 170,\n",
       "          'feel': 229,\n",
       "          'suddenly': 45,\n",
       "          'found': 117,\n",
       "          'whole': 129,\n",
       "          'casting': 43,\n",
       "          'doogie': 2,\n",
       "          'howser': 2,\n",
       "          'neil': 15,\n",
       "          'patrick': 20,\n",
       "          'mind': 166,\n",
       "          'military': 17,\n",
       "          'intelligence': 35,\n",
       "          'guilty': 13,\n",
       "          'pleasure': 38,\n",
       "          'starship': 11,\n",
       "          'trooper': 12,\n",
       "          'hugely': 6,\n",
       "          'entertaining': 111,\n",
       "          'mega': 6,\n",
       "          'budgeted': 3,\n",
       "          'sci': 30,\n",
       "          'fi': 30,\n",
       "          'yarn': 3,\n",
       "          'directed': 110,\n",
       "          'paul': 52,\n",
       "          'verhoeven': 7,\n",
       "          'making': 184,\n",
       "          'recovery': 3,\n",
       "          'g': 27,\n",
       "          'string': 28,\n",
       "          'epic': 43,\n",
       "          'showgirl': 3,\n",
       "          'qualifies': 3,\n",
       "          'cinematic': 44,\n",
       "          'junk': 8,\n",
       "          'food': 26,\n",
       "          'forgivable': 2,\n",
       "          'tasty': 2,\n",
       "          'everyone': 136,\n",
       "          'need': 151,\n",
       "          'high': 170,\n",
       "          'calorie': 2,\n",
       "          'change': 118,\n",
       "          'pace': 51,\n",
       "          'onslaught': 1,\n",
       "          'costume': 45,\n",
       "          'drama': 104,\n",
       "          'assorted': 3,\n",
       "          'oscar': 99,\n",
       "          'bait': 4,\n",
       "          'job': 179,\n",
       "          'admirably': 8,\n",
       "          'flaw': 72,\n",
       "          'cheeky': 3,\n",
       "          'futuristic': 11,\n",
       "          'hybrid': 5,\n",
       "          'saved': 8,\n",
       "          'bell': 7,\n",
       "          'jane': 25,\n",
       "          'distant': 14,\n",
       "          'ahead': 22,\n",
       "          'school': 91,\n",
       "          'grad': 1,\n",
       "          'johnny': 11,\n",
       "          'rico': 5,\n",
       "          'casper': 5,\n",
       "          'van': 43,\n",
       "          'dien': 3,\n",
       "          'sign': 39,\n",
       "          'federal': 14,\n",
       "          'service': 19,\n",
       "          'along': 167,\n",
       "          'girlfriend': 62,\n",
       "          'carmen': 4,\n",
       "          'denise': 8,\n",
       "          'richards': 8,\n",
       "          'accepted': 9,\n",
       "          'mobile': 7,\n",
       "          'infantry': 2,\n",
       "          'want': 286,\n",
       "          'fleet': 2,\n",
       "          'academy': 45,\n",
       "          'become': 171,\n",
       "          'pilot': 18,\n",
       "          'couple': 121,\n",
       "          'broken': 21,\n",
       "          'temptation': 8,\n",
       "          'awaiting': 9,\n",
       "          'form': 98,\n",
       "          'dina': 2,\n",
       "          'meyer': 5,\n",
       "          'also': 420,\n",
       "          'still': 268,\n",
       "          'harboring': 2,\n",
       "          'crush': 11,\n",
       "          'attracts': 4,\n",
       "          'eye': 152,\n",
       "          'flirtatious': 1,\n",
       "          'instructor': 3,\n",
       "          'muldoon': 2,\n",
       "          'personal': 72,\n",
       "          'rivalry': 3,\n",
       "          'sexual': 47,\n",
       "          'jealousy': 8,\n",
       "          'carry': 53,\n",
       "          'final': 115,\n",
       "          'impending': 4,\n",
       "          'alien': 87,\n",
       "          'menace': 24,\n",
       "          'threatening': 16,\n",
       "          'presence': 57,\n",
       "          'obliterates': 2,\n",
       "          'part': 242,\n",
       "          'america': 74,\n",
       "          'killing': 29,\n",
       "          'parent': 78,\n",
       "          'destroying': 5,\n",
       "          'weakening': 1,\n",
       "          'lovesick': 1,\n",
       "          'protagonist': 39,\n",
       "          'given': 127,\n",
       "          'new': 286,\n",
       "          'reason': 142,\n",
       "          'dispatched': 4,\n",
       "          'group': 105,\n",
       "          'fellow': 34,\n",
       "          'fighter': 13,\n",
       "          'planet': 40,\n",
       "          'head': 138,\n",
       "          'ground': 40,\n",
       "          'assault': 10,\n",
       "          'threat': 24,\n",
       "          'enemy': 25,\n",
       "          'smarter': 5,\n",
       "          'diabolical': 5,\n",
       "          'numerous': 36,\n",
       "          'guy': 204,\n",
       "          'initial': 22,\n",
       "          'walloping': 1,\n",
       "          'must': 182,\n",
       "          'examine': 4,\n",
       "          'strategy': 6,\n",
       "          'exposition': 6,\n",
       "          'played': 191,\n",
       "          'soap': 12,\n",
       "          'opera': 26,\n",
       "          'silly': 35,\n",
       "          'aware': 25,\n",
       "          'ridiculousness': 2,\n",
       "          'enough': 227,\n",
       "          'merit': 18,\n",
       "          'smile': 32,\n",
       "          'groan': 3,\n",
       "          'campy': 7,\n",
       "          'character': 688,\n",
       "          'introduction': 11,\n",
       "          'boring': 33,\n",
       "          'training': 15,\n",
       "          'session': 11,\n",
       "          'kick': 19,\n",
       "          'gear': 12,\n",
       "          'gruesomely': 2,\n",
       "          'violent': 41,\n",
       "          'action': 215,\n",
       "          'fury': 8,\n",
       "          'severed': 4,\n",
       "          'limb': 7,\n",
       "          'decapitation': 2,\n",
       "          'disembowelment': 3,\n",
       "          'brain': 32,\n",
       "          'removal': 6,\n",
       "          'explosion': 26,\n",
       "          'jolt': 5,\n",
       "          'inducer': 1,\n",
       "          'please': 25,\n",
       "          'lucky': 23,\n",
       "          'dodge': 4,\n",
       "          'getting': 112,\n",
       "          'carded': 1,\n",
       "          'caught': 45,\n",
       "          'deservedly': 3,\n",
       "          'r': 50,\n",
       "          'rated': 53,\n",
       "          'creature': 43,\n",
       "          'design': 43,\n",
       "          'special': 132,\n",
       "          'effect': 172,\n",
       "          'amazing': 71,\n",
       "          'expected': 36,\n",
       "          'interaction': 18,\n",
       "          'human': 162,\n",
       "          'realistic': 65,\n",
       "          'imaginative': 21,\n",
       "          'point': 206,\n",
       "          'nice': 100,\n",
       "          'intergalactic': 2,\n",
       "          'beasties': 1,\n",
       "          'derivative': 5,\n",
       "          'titular': 3,\n",
       "          'monster': 41,\n",
       "          'appropriately': 22,\n",
       "          'terrifying': 13,\n",
       "          'sight': 37,\n",
       "          'especially': 162,\n",
       "          'arachnid': 2,\n",
       "          'spider': 8,\n",
       "          'scorpion': 2,\n",
       "          'crab': 3,\n",
       "          'combo': 4,\n",
       "          'sharp': 28,\n",
       "          'talon': 1,\n",
       "          'even': 422,\n",
       "          'sharper': 3,\n",
       "          'leg': 18,\n",
       "          'attack': 43,\n",
       "          'hundred': 37,\n",
       "          'funny': 165,\n",
       "          'scary': 33,\n",
       "          'bug': 25,\n",
       "          'repeated': 10,\n",
       "          'crawl': 6,\n",
       "          'jerk': 14,\n",
       "          'struggle': 36,\n",
       "          'towards': 69,\n",
       "          'intended': 32,\n",
       "          'victim': 52,\n",
       "          'determined': 27,\n",
       "          'gooey': 2,\n",
       "          'mess': 28,\n",
       "          'matter': 128,\n",
       "          'laughable': 8,\n",
       "          'master': 55,\n",
       "          'plan': 73,\n",
       "          'ask': 41,\n",
       "          'specie': 13,\n",
       "          'capable': 22,\n",
       "          'carrying': 17,\n",
       "          'sequence': 179,\n",
       "          'insect': 6,\n",
       "          'warfare': 3,\n",
       "          'bloody': 20,\n",
       "          'immensely': 12,\n",
       "          'satisfying': 36,\n",
       "          'cast': 204,\n",
       "          'member': 94,\n",
       "          'death': 111,\n",
       "          'resolution': 21,\n",
       "          'love': 295,\n",
       "          'triangle': 7,\n",
       "          'botched': 6,\n",
       "          'testament': 12,\n",
       "          'fails': 26,\n",
       "          'create': 67,\n",
       "          'strong': 102,\n",
       "          'outstanding': 43,\n",
       "          'bland': 11,\n",
       "          'ken': 5,\n",
       "          'barbie': 5,\n",
       "          'archetype': 4,\n",
       "          'serve': 23,\n",
       "          'story': 443,\n",
       "          'adequately': 4,\n",
       "          'keep': 190,\n",
       "          'distraction': 13,\n",
       "          'arm': 34,\n",
       "          'length': 37,\n",
       "          'restrain': 2,\n",
       "          'achieving': 4,\n",
       "          'higher': 22,\n",
       "          'la': 42,\n",
       "          'war': 117,\n",
       "          'slightest': 8,\n",
       "          'definite': 16,\n",
       "          'personality': 52,\n",
       "          'acting': 181,\n",
       "          'decent': 40,\n",
       "          'spectacular': 37,\n",
       "          'performer': 22,\n",
       "          'hail': 6,\n",
       "          'aaron': 5,\n",
       "          'spelling': 4,\n",
       "          'territory': 9,\n",
       "          'smallish': 2,\n",
       "          'beverly': 6,\n",
       "          'hill': 28,\n",
       "          'melrose': 2,\n",
       "          'occasionally': 40,\n",
       "          'example': 105,\n",
       "          'limited': 36,\n",
       "          'perfectly': 71,\n",
       "          'likeable': 19,\n",
       "          'smaller': 10,\n",
       "          'afore': 2,\n",
       "          'mentioned': 25,\n",
       "          'jake': 19,\n",
       "          'busey': 3,\n",
       "          'gary': 19,\n",
       "          'son': 96,\n",
       "          'sidekick': 23,\n",
       "          'latter': 40,\n",
       "          'excels': 7,\n",
       "          'creep': 11,\n",
       "          'frighteners': 2,\n",
       "          'contact': 29,\n",
       "          'kilter': 6,\n",
       "          'banana': 8,\n",
       "          'based': 132,\n",
       "          'novel': 70,\n",
       "          'robert': 82,\n",
       "          'heinlein': 2,\n",
       "          'writer': 114,\n",
       "          'recent': 75,\n",
       "          'adaptation': 28,\n",
       "          'justice': 31,\n",
       "          'done': 147,\n",
       "          'book': 107,\n",
       "          'howler': 2,\n",
       "          'puppet': 6,\n",
       "          'familiarity': 2,\n",
       "          'trilogy': 18,\n",
       "          'promise': 32,\n",
       "          'great': 286,\n",
       "          'gob': 2,\n",
       "          'gore': 29,\n",
       "          'could': 285,\n",
       "          'drawer': 4,\n",
       "          'influence': 18,\n",
       "          'might': 162,\n",
       "          'franchise': 15,\n",
       "          'continuation': 1,\n",
       "          'resurrection': 5,\n",
       "          'open': 121,\n",
       "          'week': 60,\n",
       "          'crown': 4,\n",
       "          'summer': 87,\n",
       "          'figured': 8,\n",
       "          'alfred': 7,\n",
       "          'hitchcock': 13,\n",
       "          'dozen': 28,\n",
       "          'complaining': 8,\n",
       "          'suspense': 41,\n",
       "          'understatement': 8,\n",
       "          'paradine': 1,\n",
       "          'case': 115,\n",
       "          'admittedly': 12,\n",
       "          'lesser': 17,\n",
       "          'turned': 73,\n",
       "          'missed': 22,\n",
       "          'worth': 99,\n",
       "          'savoring': 2,\n",
       "          'rich': 71,\n",
       "          'mr': 73,\n",
       "          'maddalena': 1,\n",
       "          'anna': 14,\n",
       "          'arrested': 8,\n",
       "          'poisoning': 3,\n",
       "          'blind': 19,\n",
       "          'husband': 72,\n",
       "          'alida': 2,\n",
       "          'valli': 2,\n",
       "          'aloof': 3,\n",
       "          'alluring': 5,\n",
       "          'woman': 200,\n",
       "          'franz': 4,\n",
       "          'waxman': 1,\n",
       "          'stark': 12,\n",
       "          'moody': 10,\n",
       "          'music': 133,\n",
       "          'prison': 35,\n",
       "          'guard': 33,\n",
       "          'divesting': 1,\n",
       "          'luxurious': 4,\n",
       "          'garment': 2,\n",
       "          'jewel': 5,\n",
       "          'stripped': 8,\n",
       "          'raiment': 1,\n",
       "          'becomes': 151,\n",
       "          'commoner': 3,\n",
       "          'turn': 243,\n",
       "          'met': 24,\n",
       "          'brief': 43,\n",
       "          'skirmish': 1,\n",
       "          'lunching': 1,\n",
       "          'savoy': 1,\n",
       "          'anthony': 24,\n",
       "          'keane': 1,\n",
       "          'ultraconfident': 1,\n",
       "          'attorney': 15,\n",
       "          'meeting': 26,\n",
       "          'predicting': 1,\n",
       "          'fast': 51,\n",
       "          'easy': 68,\n",
       "          'trial': 21,\n",
       "          'gregory': 5,\n",
       "          'peck': 4,\n",
       "          'successful': 65,\n",
       "          'debonair': 1,\n",
       "          'barrister': 1,\n",
       "          'murderess': 1,\n",
       "          'argues': 4,\n",
       "          'simplistically': 2,\n",
       "          'smitten': 9,\n",
       "          'beauty': 44,\n",
       "          'attitude': 44,\n",
       "          'upset': 14,\n",
       "          'increasing': 7,\n",
       "          'jealous': 11,\n",
       "          'gay': 30,\n",
       "          'ann': 7,\n",
       "          'todd': 7,\n",
       "          'unlike': 72,\n",
       "          'centered': 8,\n",
       "          'thriller': 71,\n",
       "          'mystery': 57,\n",
       "          'romantic': 61,\n",
       "          'melodrama': 10,\n",
       "          'typical': 50,\n",
       "          'fling': 2,\n",
       "          'back': 264,\n",
       "          'shake': 7,\n",
       "          'hair': 37,\n",
       "          'bathed': 2,\n",
       "          'deflects': 1,\n",
       "          'affection': 26,\n",
       "          'beginning': 86,\n",
       "          'client': 13,\n",
       "          'dwells': 2,\n",
       "          'nearby': 16,\n",
       "          'relatively': 30,\n",
       "          'unsatisfying': 4,\n",
       "          'happens': 60,\n",
       "          'domestic': 12,\n",
       "          'squabble': 6,\n",
       "          'overtone': 5,\n",
       "          'intense': 40,\n",
       "          'adulterous': 2,\n",
       "          'desire': 43,\n",
       "          'sound': 118,\n",
       "          'sweeping': 9,\n",
       "          'violin': 5,\n",
       "          'acquitted': 1,\n",
       "          'dy': 33,\n",
       "          'heart': 114,\n",
       "          'freed': 6,\n",
       "          'able': 103,\n",
       "          'forget': 39,\n",
       "          'mysterious': 46,\n",
       "          'louis': 8,\n",
       "          'jordan': 11,\n",
       "          'valet': 1,\n",
       "          'discussed': 8,\n",
       "          'charles': 20,\n",
       "          'coburn': 5,\n",
       "          'legal': 11,\n",
       "          'partner': 30,\n",
       "          'sir': 15,\n",
       "          'simon': 15,\n",
       "          'flaquer': 1,\n",
       "          'laughton': 1,\n",
       "          'judge': 29,\n",
       "          'lord': 30,\n",
       "          'horfield': 1,\n",
       "          'proper': 19,\n",
       "          'british': 40,\n",
       "          'society': 53,\n",
       "          'dine': 1,\n",
       "          'long': 215,\n",
       "          'court': 31,\n",
       "          'tv': 78,\n",
       "          'junky': 2,\n",
       "          'many': 297,\n",
       "          'difference': 50,\n",
       "          'others': 118,\n",
       "          'judicial': 1,\n",
       "          'system': 37,\n",
       "          'cannot': 51,\n",
       "          'speak': 37,\n",
       "          'recess': 2,\n",
       "          'process': 36,\n",
       "          'testifying': 1,\n",
       "          'thinking': 45,\n",
       "          'nomination': 37,\n",
       "          'lady': 28,\n",
       "          'sophie': 4,\n",
       "          'ethel': 3,\n",
       "          'barrymore': 12,\n",
       "          'got': 102,\n",
       "          'supporting': 96,\n",
       "          'actress': 76,\n",
       "          'inconsequential': 5,\n",
       "          'obligatory': 18,\n",
       "          'walk': 49,\n",
       "          'train': 34,\n",
       "          'station': 26,\n",
       "          'large': 59,\n",
       "          'musical': 51,\n",
       "          'instrument': 7,\n",
       "          'miss': 45,\n",
       "          'finally': 106,\n",
       "          'alive': 43,\n",
       "          'courtroom': 21,\n",
       "          'hand': 166,\n",
       "          'build': 51,\n",
       "          'rapidly': 7,\n",
       "          'lay': 16,\n",
       "          'fallow': 1,\n",
       "          'angle': 24,\n",
       "          'exact': 21,\n",
       "          'tone': 54,\n",
       "          'explains': 24,\n",
       "          'simple': 103,\n",
       "          'possibility': 20,\n",
       "          'poisoned': 1,\n",
       "          'includes': 30,\n",
       "          'devastating': 10,\n",
       "          'revelation': 21,\n",
       "          'twist': 59,\n",
       "          'languid': 1,\n",
       "          'run': 150,\n",
       "          'black': 111,\n",
       "          'white': 81,\n",
       "          'pg': 30,\n",
       "          'mature': 25,\n",
       "          'theme': 81,\n",
       "          'kid': 137,\n",
       "          'nine': 12,\n",
       "          'interested': 39,\n",
       "          'crash': 28,\n",
       "          'surface': 25,\n",
       "          'unerotic': 1,\n",
       "          'porn': 9,\n",
       "          'name': 126,\n",
       "          'start': 189,\n",
       "          'cool': 51,\n",
       "          'camerawork': 8,\n",
       "          'mean': 134,\n",
       "          'left': 128,\n",
       "          'completely': 116,\n",
       "          'bored': 19,\n",
       "          'unsatisfied': 4,\n",
       "          'generally': 36,\n",
       "          'kinda': 9,\n",
       "          'weirded': 1,\n",
       "          'supposed': 54,\n",
       "          'leave': 82,\n",
       "          'entertained': 10,\n",
       "          'structured': 8,\n",
       "          'flick': 90,\n",
       "          'significantly': 6,\n",
       "          'dialogue': 121,\n",
       "          'several': 130,\n",
       "          'extremely': 100,\n",
       "          'taboo': 7,\n",
       "          'weirdo': 1,\n",
       "          'sex': 83,\n",
       "          'skimpy': 1,\n",
       "          'mostly': 76,\n",
       "          'maybe': 65,\n",
       "          'characterization': 33,\n",
       "          'mention': 35,\n",
       "          'pretty': 118,\n",
       "          'lot': 219,\n",
       "          'exposed': 8,\n",
       "          'supremely': 3,\n",
       "          'different': 149,\n",
       "          'fact': 212,\n",
       "          'erotic': 9,\n",
       "          'experience': 116,\n",
       "          'pose': 8,\n",
       "          'hypnotism': 2,\n",
       "          'henry': 16,\n",
       "          'june': 7,\n",
       "          'plain': 25,\n",
       "          'horniness': 1,\n",
       "          'deep': 66,\n",
       "          'throat': 12,\n",
       "          'auto': 5,\n",
       "          'eroticism': 3,\n",
       "          'erotically': 1,\n",
       "          'present': 89,\n",
       "          'edge': 49,\n",
       "          'catherine': 10,\n",
       "          'deborah': 4,\n",
       "          'kara': 2,\n",
       "          'ungar': 1,\n",
       "          'game': 93,\n",
       "          'pressing': 2,\n",
       "          'bare': 9,\n",
       "          'breast': 9,\n",
       "          'car': 83,\n",
       "          'public': 38,\n",
       "          'air': 40,\n",
       "          'hangar': 1,\n",
       "          'enters': 17,\n",
       "          'frame': 26,\n",
       "          'behind': 122,\n",
       "          'doesnt': 1,\n",
       "          'though': 238,\n",
       "          'nc': 12,\n",
       "          'next': 136,\n",
       "          'james': 111,\n",
       "          ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_word_freq=FreqDist()\n",
    "neg_word_freq=FreqDist()\n",
    "\n",
    "for reviewDist,label in training_prepros:\n",
    "    if label=='pos':\n",
    "        pos_word_freq+=reviewDist\n",
    "    else:\n",
    "        neg_word_freq+=reviewDist\n",
    "        \n",
    "pos_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlV2uiIg16ms",
    "outputId": "5f686417-a727-499b-aeb8-51b5b0d1ec8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22511"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vqmd3A51eOXk",
    "outputId": "cdefa01a-9894-4af6-82df-d2ccc4868175"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGm7xshkeOXk",
    "outputId": "8592d802-4345-4874-b9e2-458a2dd18051"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_word_freq['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6s15X4R2cWz",
    "outputId": "263ddb94-02b7-49bd-a173-867f3fb22fea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_word_freq['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CRGhKdV82guI"
   },
   "outputs": [],
   "source": [
    "def most_frequent_words(freq1, freq2, k):\n",
    "    diff=freq1-freq2\n",
    "    sortedvalues=diff.most_common()\n",
    "    words=[word for (word,freq) in sortedvalues[:k]]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GBhiZe6y2wW8"
   },
   "outputs": [],
   "source": [
    "my_positive_word_list=most_frequent_words(pos_word_freq,neg_word_freq, 10)\n",
    "my_negative_word_list=most_frequent_words(neg_word_freq,pos_word_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dE2ItqOU7h3A",
    "outputId": "03134b2f-458e-4edd-eda3-0c2483523364"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['performance',\n",
       " 'life',\n",
       " 'great',\n",
       " 'world',\n",
       " 'take',\n",
       " 'year',\n",
       " 'see',\n",
       " 'also',\n",
       " 'american',\n",
       " 'best']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_positive_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5v9OSiah7wIN",
    "outputId": "02332ac3-eba1-4185-df29-ea2c10eb9b3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad',\n",
       " 'minute',\n",
       " 'plot',\n",
       " 'boring',\n",
       " 'worst',\n",
       " 'attempt',\n",
       " 'stupid',\n",
       " 'nothing',\n",
       " 'joke',\n",
       " 'least']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_negative_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TApOQE6vND20"
   },
   "source": [
    "2) \n",
    "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
    "\n",
    "b) **Explain** what you have done.\n",
    "\n",
    "[12.5\\%]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg-PnS6_sIle"
   },
   "source": [
    "## **2.b.  Process explained for building a *Word list classifier*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBKeCo06hdcQ"
   },
   "source": [
    "By using the positive and negative word lists created, a word list classifier is built.A classifier named SimpleClassifier is built which classified the movie_reviews, depending on the score. The score is incremented if the word in the doc is from positive, and the score is decreased if the word in the doc is from negative. Finally the review was classified as positive if the score is greater than 0 and negative if it is less than 0. Using this SimpleClassifier another classifier named SimpleClassifier_mf is built with most_frequent_words function which is used to classify the reviews. Now the training data is used for training this SimpleClassifier_mf classifier and it was tested on testing data.After testing, the model gave the predicted values for all the testing_prepos data which is used for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XN1gs0Poqqsw"
   },
   "source": [
    "## **2.a. Building a *Word list classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8BMw2TpfeOXn",
    "outputId": "beb039e1-4860-4643-8f6c-d52923cebcb5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from nltk.classify.api import ClassifierI\n",
    "import random\n",
    "\n",
    "class SimpleClassifier(ClassifierI): \n",
    "\n",
    "    def __init__(self, pos, neg): \n",
    "        self._pos = pos \n",
    "        self._neg = neg \n",
    "\n",
    "    def classify(self, doc): \n",
    "        score = 0\n",
    "        \n",
    "        # add code here that assigns an appropriate value to score\n",
    "        for word, value in doc.items():\n",
    "            if word in self._pos:\n",
    "                score+=value\n",
    "            if word in self._neg:\n",
    "                score-=value\n",
    "        return \"neg\" if score < 0 else \"pos\"\n",
    "\n",
    "    ##we don't actually need to define the classify_many method as it is provided in ClassifierI\n",
    "    #def classify_many(self, docs): \n",
    "    #    return [self.classify(doc) for doc in docs] \n",
    "\n",
    "    def labels(self): \n",
    "        return (\"pos\", \"neg\")\n",
    "\n",
    "#Example usage:\n",
    "\n",
    "classifier = SimpleClassifier(my_positive_word_list, my_negative_word_list)\n",
    "classifier.classify(FreqDist(\"This movie was great\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "g_0aBYCyCQiR"
   },
   "outputs": [],
   "source": [
    "class SimpleClassifier_mf(SimpleClassifier):\n",
    "    \n",
    "    def __init__(self,k):\n",
    "        self._k=k\n",
    "    \n",
    "    def train(self,training_data):\n",
    "        \n",
    "        pos_word_freq=FreqDist()\n",
    "        neg_word_freq=FreqDist()\n",
    "\n",
    "        for reviewDist,label in training_data:\n",
    "            if label=='pos':\n",
    "                pos_word_freq+=reviewDist\n",
    "            else:\n",
    "                neg_word_freq+=reviewDist\n",
    "                \n",
    "        self._pos=most_frequent_words(pos_word_freq,neg_word_freq,self._k)\n",
    "        self._neg=most_frequent_words(neg_word_freq,pos_word_freq,self._k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "abvxEtpveOXn"
   },
   "outputs": [],
   "source": [
    "movieclassifier_most_frequent_words=SimpleClassifier_mf(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "c3rF-0IFChXS"
   },
   "outputs": [],
   "source": [
    "movieclassifier_most_frequent_words.train(training_prepros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8nASW1OcCqUH",
    "outputId": "dcf8935e-8901-4b76-cc6a-5b4f1e797d8a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieclassifier_most_frequent_words.classify(FreqDist(\"I love this movie\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Quf7GVjACuQD",
    "outputId": "97750d01-a7b7-41f9-bc3e-ae893224c547"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing,labels=zip(*testing_prepros)\n",
    "movieclassifier_most_frequent_words.classify_many(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb91UlBBeOXn"
   },
   "source": [
    "3)\n",
    "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
    "\n",
    "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEbNFBaXq787"
   },
   "source": [
    "## **3.a. Calculating the accuracy, precision, recall and F1 score of *Word list classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "VdDKBoUyL2a9"
   },
   "outputs": [],
   "source": [
    "def classifier_evaluate(cls, test_data):\n",
    "    '''\n",
    "    cls: an instance of a classifier object which has a classify method which returns \"pos\" or \"neg\"\n",
    "    test_data: a list of pairs where each pair is a FreqDist rep of a doc and its label\n",
    "  \n",
    "    returns: float point number which is the accuracy of the classifier on the test data provided \n",
    "    '''\n",
    "    acc = 0\n",
    "    docs,goldstandard=zip(*test_data) #note this neat pythonic way of turning a list of pairs into a pair of lists\n",
    "    #pass all of the docs to the classifier and get back a list of predictions\n",
    "    predictions=cls.classify_many(docs)\n",
    "    #zip the predictions with the goldstandard labels and compare\n",
    "    for prediction,goldlabel in zip(predictions,goldstandard):\n",
    "        if prediction==goldlabel:\n",
    "            acc+=1\n",
    "    \n",
    "    return acc / (len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7dB9PItL0sN",
    "outputId": "8efec328-df4a-4063-ddc7-3734410d51e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.33333333333333\n"
     ]
    }
   ],
   "source": [
    "score = classifier_evaluate(movieclassifier_most_frequent_words, testing_prepros)  \n",
    "print(score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "x4_mWxjTEBI_"
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self,predictions,goldstandard,classes=(\"pos\",\"neg\")):\n",
    "    \n",
    "        (self.c1,self.c2)=classes\n",
    "        self.TP=0\n",
    "        self.FP=0\n",
    "        self.FN=0\n",
    "        self.TN=0\n",
    "        \n",
    "        for p,g in zip(predictions,goldstandard):\n",
    "            if g==self.c1:\n",
    "                if p==self.c1:\n",
    "                    self.TP+=1\n",
    "                else:\n",
    "                    self.FN+=1\n",
    "        \n",
    "            elif p==self.c1:\n",
    "                self.FP+=1\n",
    "            else:\n",
    "                self.TN+=1\n",
    "        \n",
    "    \n",
    "    def precision(self):\n",
    "        p=0\n",
    "        #put your code to compute precision here\n",
    "        p=(self.TP/(self.TP+self.FP))\n",
    "        return p\n",
    "  \n",
    "    def recall(self):\n",
    "        r=0\n",
    "        #put your code to compute recall here\n",
    "        r=(self.TP/(self.TP+self.FN))\n",
    "        return r\n",
    "  \n",
    "    def f1(self):\n",
    "        f1=0\n",
    "        #put your code to compute f1 here\n",
    "        f1=((2*self.precision()*self.recall())/(self.precision()+self.recall()))\n",
    "        return f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkqiSyM6Ex6k",
    "outputId": "03b9e7e9-4e74-4d7f-c80a-efc494d89b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP's are 287\n",
      "FP's are 219\n",
      "TN's are 81\n",
      "FN's are 13\n",
      "The Precision is 0.567193675889328\n",
      "The Recall is  0.9566666666666667\n",
      "The f1 score is 0.7121588089330024\n"
     ]
    }
   ],
   "source": [
    "docs,labels=zip(*testing_prepros)\n",
    "senti_cm=ConfusionMatrix(movieclassifier_most_frequent_words.classify_many(docs),labels)\n",
    "print(\"TP's are\",senti_cm.TP)\n",
    "print(\"FP's are\",senti_cm.FP)\n",
    "print(\"TN's are\",senti_cm.TN)\n",
    "print(\"FN's are\",senti_cm.FN)\n",
    "print(\"The Precision is\", senti_cm.precision())\n",
    "print(\"The Recall is \",senti_cm.recall())\n",
    "print(\"The f1 score is\",senti_cm.f1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq7XHW_9irxI"
   },
   "source": [
    "## **3.b. Discussion on whether it is reasonable/not reasonable to evaluate the classifier in terms of its accuracy**\n",
    "The accuracy of the classifier is calculated with a word list of size 10. The accuracy came around 61.33%. Accuracy is the  proportion of correct predictions to the total number of cases examined(total predictions).\n",
    "\n",
    " \n",
    "\n",
    "Accuracy alone is not reasonable  to evaluate the performance of the classifier in all scenarios. Accuracy treats all the scenarios the same and given as percentage of correct responses. Accuracy may be fine when you’re dealing with balanced or approximately balanced datasets. The further you get far away from 50/50, the more it is misleading. But in the real world, not every dataset is a balanced one.\n",
    "\n",
    " \n",
    "\n",
    "To explain it further, let’s take an example of Fraud detection in the finance sector which is a high risk factor. Here the aim is to predict which transaction is a fraud. In real word most of the transactions are genuine/non-fraudulent transactions. If spoken in terms of percentages only 1% of the entire transactions are fraudulent. Predicting these 1% accurately is very important. Here the dataset is with a 99:1 ratio of genuine to fraudulent transactions. Simply predicting the majority class gives a 99% accurate classifier! But in this case we are more bothered about predicting 1% fraudulent  rather than 99% genuine transactions. In the above scenario, the classifier predicts all the cases as genuine transactions giving an accuracy of 99% neglecting the fraudulent ones. This model has great accuracy but is useless in predicting the required fraudulent cases. In this case accuracy is totally misleading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIS9UpmJNEAp"
   },
   "source": [
    "4) \n",
    "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
    "\n",
    "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results. \n",
    "\n",
    "[12.5\\%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFOdB4g9rKij"
   },
   "source": [
    "## **4.a. Construction of  *Naive Bayes classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_ab1inAx3QoS"
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.scores import (precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XTQZs48WeOXo"
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_prepros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oyw3tJkaeOXo",
    "outputId": "d0a664f1-348c-47d2-c9b4-a2137101a6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 67.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_prepros))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9kvgXSfw4Z7r"
   },
   "outputs": [],
   "source": [
    "docs,labels=zip(*testing_prepros)\n",
    "naive_bayes_metrics=ConfusionMatrix(classifier.classify_many(docs),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcxbjD5D4_aw",
    "outputId": "9ddbae59-c4a8-4108-b4e2-49fe2e0d1e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP's are 291\n",
      "FP's are 189\n",
      "TN's are 111\n",
      "FN's are 9\n",
      "The Precision is 0.60625\n",
      "The Recall is  0.97\n",
      "The f1 score is 0.7461538461538461\n"
     ]
    }
   ],
   "source": [
    "print(\"TP's are\",naive_bayes_metrics.TP)\n",
    "print(\"FP's are\",naive_bayes_metrics.FP)\n",
    "print(\"TN's are\",naive_bayes_metrics.TN)\n",
    "print(\"FN's are\",naive_bayes_metrics.FN)\n",
    "print(\"The Precision is\", naive_bayes_metrics.precision())\n",
    "print(\"The Recall is \",naive_bayes_metrics.recall())\n",
    "print(\"The f1 score is\",naive_bayes_metrics.f1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-__qYPoZ-7aE",
    "outputId": "a9f4de31-592d-463e-b578-1a2e8ed39d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               ludicrous = 1                 neg : pos    =     21.0 : 1.0\n",
      "               affecting = 1                 pos : neg    =     11.7 : 1.0\n",
      "                   anger = 1                 pos : neg    =     11.4 : 1.0\n",
      "              astounding = 1                 pos : neg    =     11.0 : 1.0\n",
      "            breathtaking = 1                 pos : neg    =     10.6 : 1.0\n",
      "               insulting = 1                 neg : pos    =     10.3 : 1.0\n",
      "                    jedi = 1                 pos : neg    =     10.3 : 1.0\n",
      "             outstanding = 1                 pos : neg    =      9.7 : 1.0\n",
      "                seamless = 1                 pos : neg    =      9.0 : 1.0\n",
      "                  minnie = 1                 pos : neg    =      9.0 : 1.0\n",
      "           unintentional = 1                 neg : pos    =      9.0 : 1.0\n",
      "              mechanical = 1                 neg : pos    =      9.0 : 1.0\n",
      "                  darker = 1                 pos : neg    =      9.0 : 1.0\n",
      "                 garbage = 1                 neg : pos    =      8.6 : 1.0\n",
      "                 insipid = 1                 neg : pos    =      8.3 : 1.0\n",
      "                 freddie = 1                 neg : pos    =      8.3 : 1.0\n",
      "                  rehash = 1                 neg : pos    =      8.3 : 1.0\n",
      "              accessible = 1                 pos : neg    =      8.3 : 1.0\n",
      "                  avoids = 1                 pos : neg    =      8.3 : 1.0\n",
      "               performed = 1                 pos : neg    =      8.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSSkESOZeOXo"
   },
   "source": [
    "## **4.b. Performance comparision between word list classifier and Naive Bayes classifier** \n",
    "After running the models(word list classifier and Naive Bayes classifier), the performance of the Naive Bayes classifier found out to be better than word list classifier(wordlist size of 10) in terms of all metrics like accuracy, precision, recall and f1 score. The various metrics considered in the evaluation of the performance of the classifiers are discussed below. \n",
    "\n",
    "1.  When a positive example classified as positive, it is called a **true positive(TP)**.\n",
    "2.  When a positive example misclassified as negative, it is called a **false negative(FN)**.\n",
    "3.  When a negative example classified as negative, it is called a **true negative(TN)**.\n",
    "4.  When a negative example misclassified as positive, it is called a **false positive(FP)**.\n",
    "5.  **Accuracy** is the number of correct predictions to the total number of predictions.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "Accuracy=\\frac{TP+TN}{TP+FP+TN+FN}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "6.  **Precision(P)** is the ability to identify relevant instances among the total retrieved instances.\n",
    "\n",
    " \n",
    "\\begin{eqnarray*}\n",
    "P=\\frac{TP}{TP+FP}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "7.  **Recall(R)** says what proportion of actual positives/negatives were identified correctly.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "R=\\frac{TP}{TP+FN}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "8.  **F1 Score** is a way of joining the precision and recall of the model, and it is defined as the harmonic mean of the model's precision and recall. \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "F1 = \\frac{2\\times P\\times R}{P+R}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n",
    "Word list classifier, True Positives(TP)  are **287**,False Positives(FP) are **219**, True Negatives(TN)  are **81**, False Negatives(FN) are **13**,Precision is **0.567193675889328**, Recall is **0.9566666666666667**, f1 score is **0.7121588089330024**, accuracy is **61.33333333333333%** \n",
    "\n",
    "Naive Bayes classifier True Positives(TP)  are **291**,False Positives(FP) are **189**, True Negatives(TN)  are **111**, False Negatives(FN) are **9**,Precision is **0.60625**, Recall is  **0.97**,f1 score is **0.7461538461538461**, accuracy is **67.0%**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGDXaVDqOSfY"
   },
   "source": [
    "5) \n",
    "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions. \n",
    "\n",
    "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
    "\n",
    "[25\\%]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TlFmTv_eOXo"
   },
   "source": [
    "## **5.a. An experiment into the impact of the length of the wordlists on the wordlist classifier**\n",
    "The  impact of the length of the wordlists on the wordlist classifier is found out by designing an experiment where the size of the wordlist is varied every time and the model is trained using updated wordlist and the impact is calculated using the accuracy metric. Here, the accuracy is selected as a performance evaluation metric because the movie reviews set used here is a balanced dataset. It has a total of 1000 positive reviews and 1000 negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iEgEdZGeOXp",
    "outputId": "aab775f4-9b95-4c3c-e59b-51868e7f1dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 10 is 61.33333333333333\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 20 is 56.49999999999999\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 30 is 66.5\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 40 is 65.33333333333333\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 50 is 66.0\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 60 is 64.33333333333333\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 70 is 69.5\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 80 is 68.83333333333333\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 90 is 71.16666666666667\n",
      "The accuracy of SimpleClassifier_mf classifier with wordlist size 100 is 72.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{10: 61.33333333333333,\n",
       " 20: 56.49999999999999,\n",
       " 30: 66.5,\n",
       " 40: 65.33333333333333,\n",
       " 50: 66.0,\n",
       " 60: 64.33333333333333,\n",
       " 70: 69.5,\n",
       " 80: 68.83333333333333,\n",
       " 90: 71.16666666666667,\n",
       " 100: 72.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "wordlist_size=[10,20,30,40,50,60,70,80,90,100]\n",
    "results={}\n",
    "for x in wordlist_size:\n",
    "    Word_List_MF=SimpleClassifier_mf(x)\n",
    "    Word_List_MF.train(training_prepros)\n",
    "    #docs,labels=zip(*testing_prepros)\n",
    "    accuracy=classifier_evaluate(Word_List_MF, testing_prepros) \n",
    "    print(\"The accuracy of SimpleClassifier_mf classifier with wordlist size {} is {}\".format(x, accuracy*100))\n",
    "    results[x]=accuracy*100\n",
    "\n",
    "results           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "rEIzWqFKeOXp",
    "outputId": "bb7119fe-35d9-4e10-aaf4-237e9b548cc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>66.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>65.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>64.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>69.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>68.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>71.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy\n",
       "10   61.333333\n",
       "20   56.500000\n",
       "30   66.500000\n",
       "40   65.333333\n",
       "50   66.000000\n",
       "60   64.333333\n",
       "70   69.500000\n",
       "80   68.833333\n",
       "90   71.166667\n",
       "100  72.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(results, index=[0])\n",
    "df=df.transpose()\n",
    "\n",
    "df.columns = ['Accuracy']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "RxMxZuXZeOXp",
    "outputId": "9a6d9207-331a-452c-9cdc-405d68134c78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Word list size')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df.plot(kind=\"line\",title=\"Experimental Results\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Word list size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsljTtuxeOXp"
   },
   "source": [
    "## **5.b. My Recommendation**\n",
    "\n",
    "From the experiment, it was evident that the word list classifier with the word list size 70 and above 70 has performed better than naïve bayes. The accuracy of Naïve bayes was 67.0%, while the accuracy of word list classifier (wordlist size >=70) seemed to be increased and was around 72% for wordlist of size 100. \n",
    "\n",
    "Taking all these into consideration, I would recommend a wordlist classifier for future work in this area when compared to Naïve Bayes.In real word problems, I believe that the word list size would be huge, and hence a word list classifier would perform better in those scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qC9zSw7Wom1p",
    "outputId": "30fa9e3d-91cf-4b64-b747-e7a4a4687ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34rdlS_iPov6",
    "outputId": "b0f8b920-f9ff-4746-beb0-d3e4955421d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nbformat/current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission length is 1216\n"
     ]
    }
   ],
   "source": [
    "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
    "##Running it before providing any answers shows that the questions have a word count of 437\n",
    "\n",
    "import io\n",
    "from nbformat import current\n",
    "\n",
    "#filepath=\"/content/drive/My Drive/NLE Notebooks/assessment/assignment1.ipynb\"\n",
    "filepath=\"/content/drive/My Drive/Colab Notebooks/AppNLP_Notebooks/Assignments/PG2021/NLassignment2021.ipynb\"\n",
    "question_count=437\n",
    "\n",
    "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print(\"Submission length is {}\".format(word_count-question_count))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLassignment2021 (1) (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
